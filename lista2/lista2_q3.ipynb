{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~bstra (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~bstra (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~bstra (C:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertviz in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers>=2.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (4.45.2)\n",
      "Requirement already satisfied: torch>=1.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (4.66.5)\n",
      "Requirement already satisfied: boto3 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (1.35.49)\n",
      "Requirement already satisfied: requests in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (2.32.3)\n",
      "Requirement already satisfied: regex in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (2024.9.11)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bertviz) (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (73.0.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.0->bertviz) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.0->bertviz) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=2.0->bertviz) (0.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->bertviz) (0.4.6)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.49 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3->bertviz) (1.35.78)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3->bertviz) (0.10.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->bertviz) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->bertviz) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->bertviz) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->bertviz) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from botocore<1.36.0,>=1.35.49->boto3->bertviz) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bielv\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.49->boto3->bertviz) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-259bed898bfe4c7c8f550a89eb9a061d\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                Layer: <select id=\"layer\"></select>\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "/**\n * @fileoverview Transformer Visualization D3 javascript code.\n *\n *\n *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n *\n * Change log:\n *\n * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n * 12/29/20  Jesse Vig   Significant refactor.\n * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n * 07/25/21  Jesse Vig   Support layer filtering\n * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n **/\n\nrequire.config({\n  paths: {\n      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n  }\n});\n\nrequirejs(['jquery', 'd3'], function ($, d3) {\n\n    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.010165569758927066, 0.0, 0.025700553151966767, 0.007178199246564331, 0.007880069570889702, 0.0, 0.035133063320172825, 0.010555754236587065, 0.08951417648938464, 0.004869283371446546, 0.0047443801151497095, 0.014343764670858844, 0.02445217227521635, 0.02995774684943825, 0.03347700360493521, 0.0, 0.0, 0.0, 0.0, 0.024185541482555778, 0.0, 0.009177640949648395, 0.006095317847094681, 0.0, 0.016427908691655866, 0.0, 0.0, 0.0, 0.03916136295235433, 0.021935268723387857, 0.005071740758464668], [0.010165569758927066, 0.9999999999999998, 0.0, 0.013772360451971877, 0.008051699642287592, 0.013353045262547174, 0.0, 0.020523637599447767, 0.059134260003092375, 0.013083838989865338, 0.0, 0.06728352518844737, 0.011535678184728637, 0.021848875931009606, 0.0, 0.0, 0.0, 0.01399798246495333, 0.01352311174055609, 0.0, 0.03492570531470705, 0.0045491076020615666, 0.006272875226497045, 0.029295935854436052, 0.006703007880556978, 0.016643481998781184, 0.022561905048625215, 0.03399415142819739, 0.015470343168410467, 0.0, 0.011488014495506224, 0.019453471984443523], [0.0, 0.0, 0.9999999999999999, 0.0, 0.01387175786100754, 0.028586284878260086, 0.010824751113369484, 0.0, 0.04852490695244353, 0.02823322870350423, 0.0, 0.0, 0.0, 0.00666813168030251, 0.02850266140601373, 0.024779744596907568, 0.0, 0.0, 0.015760799148422846, 0.03331486014006675, 0.0, 0.0, 0.018190441707578265, 0.0559807234641116, 0.0, 0.010698539317989144, 0.015537965621719519, 0.09438274524840802, 0.05808365159698793, 0.0, 0.02757936399824741, 0.0], [0.025700553151966767, 0.013772360451971877, 0.0, 1.0000000000000002, 0.00464451727027647, 0.08893306045844086, 0.003176175189266659, 0.026129197555094484, 0.00799118357209028, 0.05588927719081718, 0.022793601632047203, 0.04350648246925324, 0.023142638861614606, 0.04638486716290954, 0.01947649363748378, 0.014527111510612306, 0.030648750724538355, 0.034964055514936615, 0.012019506362548001, 0.017198739557807333, 0.04188795659983768, 0.029678156208540498, 0.017894047711639192, 0.01309298651004118, 0.01640818700990469, 0.04522156669342009, 0.10806945435374424, 0.012531257531369383, 0.010792209366116924, 0.07342913806674714, 0.054247107800793906, 0.0], [0.007178199246564331, 0.008051699642287592, 0.01387175786100754, 0.00464451727027647, 0.9999999999999999, 0.020458716030211578, 0.017843782867925824, 0.011633877751260364, 0.013679212465130446, 0.02924770502020802, 0.014918664621384466, 0.05702582751441021, 0.0072270353425274245, 0.06569540429859981, 0.03984230632099588, 0.0, 0.0, 0.025124553117476446, 0.0, 0.011837467555193711, 0.0987522163342077, 0.031221273033637954, 0.03646127087890035, 0.025032329716393506, 0.016709587351972054, 0.03358543678990562, 0.02745667460221717, 0.030979119541277807, 0.030086033834475216, 0.017044955717240236, 0.06337159262503775, 0.02262135961222175], [0.007880069570889702, 0.013353045262547174, 0.028586284878260086, 0.08893306045844086, 0.020458716030211578, 1.0, 0.01662836343945822, 0.06110926081085472, 0.0511121231301955, 0.05461532642454251, 0.02479772616687137, 0.04694354752258781, 0.03109671628148567, 0.04919765299917562, 0.040052448796382395, 0.016859495304394005, 0.0219109292228047, 0.042146645338000804, 0.027477411820976974, 0.04865379402040577, 0.024237098035176638, 0.02068716122493726, 0.030413242373896945, 0.03625186911227815, 0.019610860383996287, 0.03461381499858542, 0.1128635260691559, 0.03420295532210278, 0.037833346112215595, 0.06809644056164116, 0.0370982708170593, 0.032201746045954174], [0.0, 0.0, 0.010824751113369484, 0.003176175189266659, 0.017843782867925824, 0.01662836343945822, 0.9999999999999998, 0.02059175512526577, 0.010003863892300999, 0.006087189129572546, 0.0013665514604383757, 0.017589073935287948, 0.0, 0.01970897967497013, 0.014595994457653935, 0.0, 0.0, 0.0, 0.0, 0.01774804261280075, 0.02283798917517596, 0.018809556013095488, 0.008876804630658142, 0.03617634741060122, 0.01755442187880152, 0.0204261718538951, 0.020180000640012418, 0.0014355181495482134, 0.05949297374985423, 0.0012770107671980396, 0.00541857810196316, 0.0028908355760221844], [0.035133063320172825, 0.020523637599447767, 0.0, 0.026129197555094484, 0.011633877751260364, 0.06110926081085472, 0.02059175512526577, 1.0000000000000002, 0.03946743000864249, 0.016091067390948843, 0.0, 0.0, 0.013467126687600566, 0.02943057446643474, 0.020430240011812106, 0.029513687029471894, 0.0, 0.008005277392453766, 0.0, 0.01077454623376135, 0.0, 0.003514332057694603, 0.025154410654098656, 0.0, 0.020305107166654988, 0.04020884146172763, 0.024054556794098503, 0.010403309402163835, 0.0, 0.050897908104059204, 0.03522308761712385, 0.007391266699602124], [0.010555754236587065, 0.059134260003092375, 0.04852490695244353, 0.00799118357209028, 0.013679212465130446, 0.0511121231301955, 0.010003863892300999, 0.03946743000864249, 1.0000000000000002, 0.011683770688351035, 0.0, 0.014901743062005868, 0.011978451455062012, 0.05012523370294304, 0.018803552474684643, 0.07313242888478778, 0.0, 0.00741490351195898, 0.00727119772973515, 0.017672696596159415, 0.01975653236993719, 0.040688696961614305, 0.0375877917325347, 0.03602757489001831, 0.011100262854647994, 0.027011720839772102, 0.05062928049630758, 0.0423809215098252, 0.04632683399728664, 0.036389870203980164, 0.01766229709438904, 0.028232601931543592], [0.08951417648938464, 0.013083838989865338, 0.02823322870350423, 0.05588927719081718, 0.02924770502020802, 0.05461532642454251, 0.006087189129572546, 0.016091067390948843, 0.011683770688351035, 1.0000000000000004, 0.01309269171241916, 0.10652089564703492, 0.013325418390911906, 0.03150136776371388, 0.051793906234511744, 0.0, 0.017039808705854656, 0.03082587064843032, 0.015190333286882697, 0.08014477137778735, 0.053951258713314826, 0.018584245292861578, 0.05394101197287035, 0.04659013379082574, 0.027665142358011725, 0.020327569810081894, 0.06000428541975659, 0.039838312578969776, 0.028541137095132348, 0.010323827270926487, 0.0465532869382955, 0.03874797810427858], [0.004869283371446546, 0.0, 0.0, 0.022793601632047203, 0.014918664621384466, 0.02479772616687137, 0.0013665514604383757, 0.0, 0.0, 0.01309269171241916, 0.9999999999999999, 0.007517666916990554, 0.006582894513613151, 0.010155046849394283, 0.01766017602087586, 0.0, 0.09329024736354027, 0.018844507109407247, 0.00536679358457379, 0.002276511186533275, 0.012188265150703599, 0.015598068154640684, 0.012299877816716763, 0.006894897685942395, 0.0015632435649459062, 0.023982454676052204, 0.02515978287256293, 0.013694784314910145, 0.0035412952849974712, 0.0015564642947462732, 0.013875907062360904, 0.044716371329394225], [0.0047443801151497095, 0.06728352518844737, 0.0, 0.04350648246925324, 0.05702582751441021, 0.04694354752258781, 0.017589073935287948, 0.0, 0.014901743062005868, 0.10652089564703492, 0.007517666916990554, 1.0, 0.0, 0.04186324381649818, 0.037230400755704385, 0.0, 0.0, 0.02002816198155088, 0.0, 0.009176972155185266, 0.02247589713324245, 0.010012987469039107, 0.01214364587682357, 0.013254425006324951, 0.0, 0.0056585761440093, 0.02203323366191245, 0.010185199002412998, 0.019018574972320946, 0.0, 0.03399595240182782, 0.018707288883587532], [0.014343764670858844, 0.011535678184728637, 0.0, 0.023142638861614606, 0.0072270353425274245, 0.03109671628148567, 0.0, 0.013467126687600566, 0.011978451455062012, 0.013325418390911906, 0.006582894513613151, 0.0, 1.0, 0.02337791036056698, 0.005611698717481173, 0.0, 0.02245562510499821, 0.037194047413175044, 0.009971889527869947, 0.013811318257831722, 0.022969192044374885, 0.0068174310703912125, 0.0, 0.038048497344584736, 0.0, 0.00676898748495482, 0.017091526695916688, 0.0, 0.006579982034163878, 0.0, 0.004979287464230278, 0.0], [0.02445217227521635, 0.021848875931009606, 0.00666813168030251, 0.04638486716290954, 0.06569540429859981, 0.04919765299917562, 0.01970897967497013, 0.02943057446643474, 0.05012523370294304, 0.03150136776371388, 0.010155046849394283, 0.04186324381649818, 0.02337791036056698, 1.0000000000000002, 0.03706558189966358, 0.04087674627839573, 0.012463592572435235, 0.025297778398393568, 0.024814023024414673, 0.025987440909028277, 0.07499905801517684, 0.029700226333322706, 0.0524615488268907, 0.055021692956443, 0.010093139628082736, 0.04259519513648398, 0.04922736168343139, 0.057530105746394264, 0.021629669152146303, 0.0181909967817958, 0.10129082810533761, 0.015607824630063178], [0.02995774684943825, 0.0, 0.02850266140601373, 0.01947649363748378, 0.03984230632099588, 0.040052448796382395, 0.014595994457653935, 0.020430240011812106, 0.018803552474684643, 0.051793906234511744, 0.01766017602087586, 0.037230400755704385, 0.005611698717481173, 0.03706558189966358, 1.0000000000000002, 0.0, 0.0, 0.005573530402071209, 0.024978422482067872, 0.0648797556521374, 0.03972188838758203, 0.03399786194069356, 0.02023965038067286, 0.059386349854446414, 0.001332613167410867, 0.08353433988064235, 0.02026807103870688, 0.014170703277900216, 0.04659249507998253, 0.043300024282500224, 0.05528710102369801, 0.011009838665022509], [0.03347700360493521, 0.0, 0.024779744596907568, 0.014527111510612306, 0.0, 0.016859495304394005, 0.0, 0.029513687029471894, 0.07313242888478778, 0.0, 0.0, 0.0, 0.0, 0.04087674627839573, 0.0, 0.9999999999999999, 0.0, 0.0, 0.0, 0.03158481020272256, 0.0, 0.0, 0.057048610638581604, 0.033056675020858635, 0.0, 0.06245189681694787, 0.0, 0.029057314736843864, 0.038968159627792126, 0.030375525068784187, 0.019499253905019887, 0.0], [0.0, 0.0, 0.0, 0.030648750724538355, 0.0, 0.0219109292228047, 0.0, 0.0, 0.0, 0.017039808705854656, 0.09329024736354027, 0.0, 0.02245562510499821, 0.012463592572435235, 0.0, 0.0, 0.9999999999999998, 0.011603619514050714, 0.0, 0.0, 0.017083967313060097, 0.0, 0.0, 0.0074043964833490445, 0.013492141972680562, 0.011246511873401295, 0.013184100529048861, 0.03171928592423446, 0.024764475499641093, 0.0, 0.0, 0.0805316486274864], [0.0, 0.01399798246495333, 0.0, 0.034964055514936615, 0.025124553117476446, 0.042146645338000804, 0.0, 0.008005277392453766, 0.00741490351195898, 0.03082587064843032, 0.018844507109407247, 0.02002816198155088, 0.037194047413175044, 0.025297778398393568, 0.005573530402071209, 0.0, 0.011603619514050714, 1.0, 0.0, 0.009714607416334937, 0.033489239473500916, 0.0033168510305547536, 0.026189406123943992, 0.03545818918285534, 0.008778838835841761, 0.040504964702762984, 0.017659090689692437, 0.030263998897218574, 0.055669543418152806, 0.07607018729385928, 0.034820671790278, 0.02684784126260703], [0.0, 0.01352311174055609, 0.015760799148422846, 0.012019506362548001, 0.0, 0.027477411820976974, 0.0, 0.0, 0.00727119772973515, 0.015190333286882697, 0.00536679358457379, 0.0, 0.009971889527869947, 0.024814023024414673, 0.024978422482067872, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0250086231668343, 0.014320829417693496, 0.03380798571236949, 0.0236964469191678, 0.003288076969902338, 0.0, 0.01620330581361451, 0.03950808080213203, 0.03099486653312298, 0.005364419146400547, 0.0, 0.014368421916653567, 0.01239564560145538], [0.0, 0.0, 0.03331486014006675, 0.017198739557807333, 0.011837467555193711, 0.04865379402040577, 0.01774804261280075, 0.01077454623376135, 0.017672696596159415, 0.08014477137778735, 0.002276511186533275, 0.009176972155185266, 0.013811318257831722, 0.025987440909028277, 0.0648797556521374, 0.03158481020272256, 0.0, 0.009714607416334937, 0.0250086231668343, 1.0000000000000004, 0.003325681912255651, 0.014340826874652097, 0.017533163626578335, 0.03328058623530883, 0.014422129686111795, 0.023651211089712555, 0.031380105578603684, 0.04142239683638839, 0.024997217124120195, 0.0, 0.0, 0.007687625064371241], [0.024185541482555778, 0.03492570531470705, 0.0, 0.04188795659983768, 0.0987522163342077, 0.024237098035176638, 0.02283798917517596, 0.0, 0.01975653236993719, 0.053951258713314826, 0.012188265150703599, 0.02247589713324245, 0.022969192044374885, 0.07499905801517684, 0.03972188838758203, 0.0, 0.017083967313060097, 0.033489239473500916, 0.014320829417693496, 0.003325681912255651, 0.9999999999999999, 0.033412288264509704, 0.061600432270586286, 0.04302635998844625, 0.011554338221945832, 0.016685495493929437, 0.027155764289425267, 0.04260739889874465, 0.05421459601984026, 0.0015138902947611122, 0.09624142177230059, 0.028688262222037093], [0.0, 0.0045491076020615666, 0.0, 0.029678156208540498, 0.031221273033637954, 0.02068716122493726, 0.018809556013095488, 0.003514332057694603, 0.040688696961614305, 0.018584245292861578, 0.015598068154640684, 0.010012987469039107, 0.0068174310703912125, 0.029700226333322706, 0.03399786194069356, 0.0, 0.0, 0.0033168510305547536, 0.03380798571236949, 0.014340826874652097, 0.033412288264509704, 1.0, 0.012188808284663769, 0.005701272996126935, 0.01195501803038374, 0.02194189209857569, 0.006619495543067105, 0.0030679753264307883, 0.003667465194140041, 0.032321874548642604, 0.01644571129061412, 0.009974088484714592], [0.009177640949648395, 0.006272875226497045, 0.018190441707578265, 0.017894047711639192, 0.03646127087890035, 0.030413242373896945, 0.008876804630658142, 0.025154410654098656, 0.0375877917325347, 0.05394101197287035, 0.012299877816716763, 0.01214364587682357, 0.0, 0.0524615488268907, 0.02023965038067286, 0.057048610638581604, 0.0, 0.026189406123943992, 0.0236964469191678, 0.017533163626578335, 0.061600432270586286, 0.012188808284663769, 1.0, 0.04153724762185301, 0.022297062806135873, 0.03164086043931865, 0.016952651209241647, 0.06500838133089702, 0.03523672783790849, 0.010342593453345776, 0.049853344622021324, 0.013175670669515114], [0.006095317847094681, 0.029295935854436052, 0.0559807234641116, 0.01309298651004118, 0.025032329716393506, 0.03625186911227815, 0.03617634741060122, 0.0, 0.03602757489001831, 0.04659013379082574, 0.006894897685942395, 0.013254425006324951, 0.038048497344584736, 0.055021692956443, 0.059386349854446414, 0.033056675020858635, 0.0074043964833490445, 0.03545818918285534, 0.003288076969902338, 0.03328058623530883, 0.04302635998844625, 0.005701272996126935, 0.04153724762185301, 0.9999999999999998, 0.016518520397363727, 0.005325482554151109, 0.032519351158622145, 0.06106465974445468, 0.08376814996267773, 0.0009536000074124221, 0.07124073155277212, 0.021821642814568033], [0.0, 0.006703007880556978, 0.0, 0.01640818700990469, 0.016709587351972054, 0.019610860383996287, 0.01755442187880152, 0.020305107166654988, 0.011100262854647994, 0.027665142358011725, 0.0015632435649459062, 0.0, 0.0, 0.010093139628082736, 0.001332613167410867, 0.0, 0.013492141972680562, 0.008778838835841761, 0.0, 0.014422129686111795, 0.011554338221945832, 0.01195501803038374, 0.022297062806135873, 0.016518520397363727, 0.9999999999999999, 0.017229043924284114, 0.020146312682282317, 0.011884293815088627, 0.004051330466862573, 0.02086024172575788, 0.028856760879540578, 0.021057594377924153], [0.016427908691655866, 0.016643481998781184, 0.010698539317989144, 0.04522156669342009, 0.03358543678990562, 0.03461381499858542, 0.0204261718538951, 0.04020884146172763, 0.027011720839772102, 0.020327569810081894, 0.023982454676052204, 0.0056585761440093, 0.00676898748495482, 0.04259519513648398, 0.08353433988064235, 0.06245189681694787, 0.011246511873401295, 0.040504964702762984, 0.01620330581361451, 0.023651211089712555, 0.016685495493929437, 0.02194189209857569, 0.03164086043931865, 0.005325482554151109, 0.017229043924284114, 1.0000000000000002, 0.014897888333724315, 0.01615845507119359, 0.017253362729950514, 0.08642585986598375, 0.019805297023117945, 0.017114102528287968], [0.0, 0.022561905048625215, 0.015537965621719519, 0.10806945435374424, 0.02745667460221717, 0.1128635260691559, 0.020180000640012418, 0.024054556794098503, 0.05062928049630758, 0.06000428541975659, 0.02515978287256293, 0.02203323366191245, 0.017091526695916688, 0.04922736168343139, 0.02026807103870688, 0.0, 0.013184100529048861, 0.017659090689692437, 0.03950808080213203, 0.031380105578603684, 0.027155764289425267, 0.006619495543067105, 0.016952651209241647, 0.032519351158622145, 0.020146312682282317, 0.014897888333724315, 1.0000000000000007, 0.01809854024774864, 0.066615236774527, 0.010487093805623, 0.06760635706395322, 0.0267133785498071], [0.0, 0.03399415142819739, 0.09438274524840802, 0.012531257531369383, 0.030979119541277807, 0.03420295532210278, 0.0014355181495482134, 0.010403309402163835, 0.0423809215098252, 0.039838312578969776, 0.013694784314910145, 0.010185199002412998, 0.0, 0.057530105746394264, 0.014170703277900216, 0.029057314736843864, 0.03171928592423446, 0.030263998897218574, 0.03099486653312298, 0.04142239683638839, 0.04260739889874465, 0.0030679753264307883, 0.06500838133089702, 0.06106465974445468, 0.011884293815088627, 0.01615845507119359, 0.01809854024774864, 1.0000000000000002, 0.019535362691424876, 0.001635015445020478, 0.053386926913070364, 0.02764702902356523], [0.0, 0.015470343168410467, 0.05808365159698793, 0.010792209366116924, 0.030086033834475216, 0.037833346112215595, 0.05949297374985423, 0.0, 0.04632683399728664, 0.028541137095132348, 0.0035412952849974712, 0.019018574972320946, 0.006579982034163878, 0.021629669152146303, 0.04659249507998253, 0.038968159627792126, 0.024764475499641093, 0.055669543418152806, 0.005364419146400547, 0.024997217124120195, 0.05421459601984026, 0.003667465194140041, 0.03523672783790849, 0.08376814996267773, 0.004051330466862573, 0.017253362729950514, 0.066615236774527, 0.019535362691424876, 0.9999999999999997, 0.006000804485983621, 0.03799339502695772, 0.003757552863971032], [0.03916136295235433, 0.0, 0.0, 0.07342913806674714, 0.017044955717240236, 0.06809644056164116, 0.0012770107671980396, 0.050897908104059204, 0.036389870203980164, 0.010323827270926487, 0.0015564642947462732, 0.0, 0.0, 0.0181909967817958, 0.043300024282500224, 0.030375525068784187, 0.0, 0.07607018729385928, 0.0, 0.0, 0.0015138902947611122, 0.032321874548642604, 0.010342593453345776, 0.0009536000074124221, 0.02086024172575788, 0.08642585986598375, 0.010487093805623, 0.001635015445020478, 0.006000804485983621, 1.0, 0.030892031842345163, 0.00994060804597145], [0.021935268723387857, 0.011488014495506224, 0.02757936399824741, 0.054247107800793906, 0.06337159262503775, 0.0370982708170593, 0.00541857810196316, 0.03522308761712385, 0.01766229709438904, 0.0465532869382955, 0.013875907062360904, 0.03399595240182782, 0.004979287464230278, 0.10129082810533761, 0.05528710102369801, 0.019499253905019887, 0.0, 0.034820671790278, 0.014368421916653567, 0.0, 0.09624142177230059, 0.01644571129061412, 0.049853344622021324, 0.07124073155277212, 0.028856760879540578, 0.019805297023117945, 0.06760635706395322, 0.053386926913070364, 0.03799339502695772, 0.030892031842345163, 0.9999999999999991, 0.022552394945273814], [0.005071740758464668, 0.019453471984443523, 0.0, 0.0, 0.02262135961222175, 0.032201746045954174, 0.0028908355760221844, 0.007391266699602124, 0.028232601931543592, 0.03874797810427858, 0.044716371329394225, 0.018707288883587532, 0.0, 0.015607824630063178, 0.011009838665022509, 0.0, 0.0805316486274864, 0.02684784126260703, 0.01239564560145538, 0.007687625064371241, 0.028688262222037093, 0.009974088484714592, 0.013175670669515114, 0.021821642814568033, 0.021057594377924153, 0.017114102528287968, 0.0267133785498071, 0.02764702902356523, 0.003757552863971032, 0.00994060804597145, 0.022552394945273814, 1.0]]]], \"left_text\": [\"comp.graphics 0\", \"sci.space 0\", \"sci.space 1\", \"comp.graphics 1\", \"alt.atheism 0\", \"comp.graphics 2\", \"sci.space 2\", \"comp.graphics 3\", \"sci.space 3\", \"rec.autos 0\", \"rec.autos 1\", \"alt.atheism 1\", \"alt.atheism 2\", \"alt.atheism 3\", \"comp.graphics 4\", \"sci.space 4\", \"rec.autos 2\", \"comp.graphics 5\", \"comp.graphics 6\", \"sci.space 5\", \"alt.atheism 4\", \"sci.space 6\", \"sci.space 7\", \"sci.space 8\", \"rec.autos 3\", \"alt.atheism 5\", \"comp.graphics 7\", \"sci.space 9\", \"sci.space 10\", \"comp.graphics 8\", \"alt.atheism 6\", \"rec.autos 4\"], \"right_text\": [\"comp.graphics 0\", \"sci.space 0\", \"sci.space 1\", \"comp.graphics 1\", \"alt.atheism 0\", \"comp.graphics 2\", \"sci.space 2\", \"comp.graphics 3\", \"sci.space 3\", \"rec.autos 0\", \"rec.autos 1\", \"alt.atheism 1\", \"alt.atheism 2\", \"alt.atheism 3\", \"comp.graphics 4\", \"sci.space 4\", \"rec.autos 2\", \"comp.graphics 5\", \"comp.graphics 6\", \"sci.space 5\", \"alt.atheism 4\", \"sci.space 6\", \"sci.space 7\", \"sci.space 8\", \"rec.autos 3\", \"alt.atheism 5\", \"comp.graphics 7\", \"sci.space 9\", \"sci.space 10\", \"comp.graphics 8\", \"alt.atheism 6\", \"rec.autos 4\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-259bed898bfe4c7c8f550a89eb9a061d\", \"layer\": null, \"heads\": null, \"include_layers\": [0]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.010165569758927066, 0.0, 0.025700553151966767, 0.007178199246564331, 0.007880069570889702, 0.0, 0.035133063320172825, 0.010555754236587065, 0.08951417648938464, 0.004869283371446546, 0.0047443801151497095, 0.014343764670858844, 0.02445217227521635, 0.02995774684943825, 0.03347700360493521, 0.0, 0.0, 0.0, 0.0, 0.024185541482555778, 0.0, 0.009177640949648395, 0.006095317847094681, 0.0, 0.016427908691655866, 0.0, 0.0, 0.0, 0.03916136295235433, 0.021935268723387857, 0.005071740758464668], [0.010165569758927066, 0.9999999999999998, 0.0, 0.013772360451971877, 0.008051699642287592, 0.013353045262547174, 0.0, 0.020523637599447767, 0.059134260003092375, 0.013083838989865338, 0.0, 0.06728352518844737, 0.011535678184728637, 0.021848875931009606, 0.0, 0.0, 0.0, 0.01399798246495333, 0.01352311174055609, 0.0, 0.03492570531470705, 0.0045491076020615666, 0.006272875226497045, 0.029295935854436052, 0.006703007880556978, 0.016643481998781184, 0.022561905048625215, 0.03399415142819739, 0.015470343168410467, 0.0, 0.011488014495506224, 0.019453471984443523], [0.0, 0.0, 0.9999999999999999, 0.0, 0.01387175786100754, 0.028586284878260086, 0.010824751113369484, 0.0, 0.04852490695244353, 0.02823322870350423, 0.0, 0.0, 0.0, 0.00666813168030251, 0.02850266140601373, 0.024779744596907568, 0.0, 0.0, 0.015760799148422846, 0.03331486014006675, 0.0, 0.0, 0.018190441707578265, 0.0559807234641116, 0.0, 0.010698539317989144, 0.015537965621719519, 0.09438274524840802, 0.05808365159698793, 0.0, 0.02757936399824741, 0.0], [0.025700553151966767, 0.013772360451971877, 0.0, 1.0000000000000002, 0.00464451727027647, 0.08893306045844086, 0.003176175189266659, 0.026129197555094484, 0.00799118357209028, 0.05588927719081718, 0.022793601632047203, 0.04350648246925324, 0.023142638861614606, 0.04638486716290954, 0.01947649363748378, 0.014527111510612306, 0.030648750724538355, 0.034964055514936615, 0.012019506362548001, 0.017198739557807333, 0.04188795659983768, 0.029678156208540498, 0.017894047711639192, 0.01309298651004118, 0.01640818700990469, 0.04522156669342009, 0.10806945435374424, 0.012531257531369383, 0.010792209366116924, 0.07342913806674714, 0.054247107800793906, 0.0], [0.007178199246564331, 0.008051699642287592, 0.01387175786100754, 0.00464451727027647, 0.9999999999999999, 0.020458716030211578, 0.017843782867925824, 0.011633877751260364, 0.013679212465130446, 0.02924770502020802, 0.014918664621384466, 0.05702582751441021, 0.0072270353425274245, 0.06569540429859981, 0.03984230632099588, 0.0, 0.0, 0.025124553117476446, 0.0, 0.011837467555193711, 0.0987522163342077, 0.031221273033637954, 0.03646127087890035, 0.025032329716393506, 0.016709587351972054, 0.03358543678990562, 0.02745667460221717, 0.030979119541277807, 0.030086033834475216, 0.017044955717240236, 0.06337159262503775, 0.02262135961222175], [0.007880069570889702, 0.013353045262547174, 0.028586284878260086, 0.08893306045844086, 0.020458716030211578, 1.0, 0.01662836343945822, 0.06110926081085472, 0.0511121231301955, 0.05461532642454251, 0.02479772616687137, 0.04694354752258781, 0.03109671628148567, 0.04919765299917562, 0.040052448796382395, 0.016859495304394005, 0.0219109292228047, 0.042146645338000804, 0.027477411820976974, 0.04865379402040577, 0.024237098035176638, 0.02068716122493726, 0.030413242373896945, 0.03625186911227815, 0.019610860383996287, 0.03461381499858542, 0.1128635260691559, 0.03420295532210278, 0.037833346112215595, 0.06809644056164116, 0.0370982708170593, 0.032201746045954174], [0.0, 0.0, 0.010824751113369484, 0.003176175189266659, 0.017843782867925824, 0.01662836343945822, 0.9999999999999998, 0.02059175512526577, 0.010003863892300999, 0.006087189129572546, 0.0013665514604383757, 0.017589073935287948, 0.0, 0.01970897967497013, 0.014595994457653935, 0.0, 0.0, 0.0, 0.0, 0.01774804261280075, 0.02283798917517596, 0.018809556013095488, 0.008876804630658142, 0.03617634741060122, 0.01755442187880152, 0.0204261718538951, 0.020180000640012418, 0.0014355181495482134, 0.05949297374985423, 0.0012770107671980396, 0.00541857810196316, 0.0028908355760221844], [0.035133063320172825, 0.020523637599447767, 0.0, 0.026129197555094484, 0.011633877751260364, 0.06110926081085472, 0.02059175512526577, 1.0000000000000002, 0.03946743000864249, 0.016091067390948843, 0.0, 0.0, 0.013467126687600566, 0.02943057446643474, 0.020430240011812106, 0.029513687029471894, 0.0, 0.008005277392453766, 0.0, 0.01077454623376135, 0.0, 0.003514332057694603, 0.025154410654098656, 0.0, 0.020305107166654988, 0.04020884146172763, 0.024054556794098503, 0.010403309402163835, 0.0, 0.050897908104059204, 0.03522308761712385, 0.007391266699602124], [0.010555754236587065, 0.059134260003092375, 0.04852490695244353, 0.00799118357209028, 0.013679212465130446, 0.0511121231301955, 0.010003863892300999, 0.03946743000864249, 1.0000000000000002, 0.011683770688351035, 0.0, 0.014901743062005868, 0.011978451455062012, 0.05012523370294304, 0.018803552474684643, 0.07313242888478778, 0.0, 0.00741490351195898, 0.00727119772973515, 0.017672696596159415, 0.01975653236993719, 0.040688696961614305, 0.0375877917325347, 0.03602757489001831, 0.011100262854647994, 0.027011720839772102, 0.05062928049630758, 0.0423809215098252, 0.04632683399728664, 0.036389870203980164, 0.01766229709438904, 0.028232601931543592], [0.08951417648938464, 0.013083838989865338, 0.02823322870350423, 0.05588927719081718, 0.02924770502020802, 0.05461532642454251, 0.006087189129572546, 0.016091067390948843, 0.011683770688351035, 1.0000000000000004, 0.01309269171241916, 0.10652089564703492, 0.013325418390911906, 0.03150136776371388, 0.051793906234511744, 0.0, 0.017039808705854656, 0.03082587064843032, 0.015190333286882697, 0.08014477137778735, 0.053951258713314826, 0.018584245292861578, 0.05394101197287035, 0.04659013379082574, 0.027665142358011725, 0.020327569810081894, 0.06000428541975659, 0.039838312578969776, 0.028541137095132348, 0.010323827270926487, 0.0465532869382955, 0.03874797810427858], [0.004869283371446546, 0.0, 0.0, 0.022793601632047203, 0.014918664621384466, 0.02479772616687137, 0.0013665514604383757, 0.0, 0.0, 0.01309269171241916, 0.9999999999999999, 0.007517666916990554, 0.006582894513613151, 0.010155046849394283, 0.01766017602087586, 0.0, 0.09329024736354027, 0.018844507109407247, 0.00536679358457379, 0.002276511186533275, 0.012188265150703599, 0.015598068154640684, 0.012299877816716763, 0.006894897685942395, 0.0015632435649459062, 0.023982454676052204, 0.02515978287256293, 0.013694784314910145, 0.0035412952849974712, 0.0015564642947462732, 0.013875907062360904, 0.044716371329394225], [0.0047443801151497095, 0.06728352518844737, 0.0, 0.04350648246925324, 0.05702582751441021, 0.04694354752258781, 0.017589073935287948, 0.0, 0.014901743062005868, 0.10652089564703492, 0.007517666916990554, 1.0, 0.0, 0.04186324381649818, 0.037230400755704385, 0.0, 0.0, 0.02002816198155088, 0.0, 0.009176972155185266, 0.02247589713324245, 0.010012987469039107, 0.01214364587682357, 0.013254425006324951, 0.0, 0.0056585761440093, 0.02203323366191245, 0.010185199002412998, 0.019018574972320946, 0.0, 0.03399595240182782, 0.018707288883587532], [0.014343764670858844, 0.011535678184728637, 0.0, 0.023142638861614606, 0.0072270353425274245, 0.03109671628148567, 0.0, 0.013467126687600566, 0.011978451455062012, 0.013325418390911906, 0.006582894513613151, 0.0, 1.0, 0.02337791036056698, 0.005611698717481173, 0.0, 0.02245562510499821, 0.037194047413175044, 0.009971889527869947, 0.013811318257831722, 0.022969192044374885, 0.0068174310703912125, 0.0, 0.038048497344584736, 0.0, 0.00676898748495482, 0.017091526695916688, 0.0, 0.006579982034163878, 0.0, 0.004979287464230278, 0.0], [0.02445217227521635, 0.021848875931009606, 0.00666813168030251, 0.04638486716290954, 0.06569540429859981, 0.04919765299917562, 0.01970897967497013, 0.02943057446643474, 0.05012523370294304, 0.03150136776371388, 0.010155046849394283, 0.04186324381649818, 0.02337791036056698, 1.0000000000000002, 0.03706558189966358, 0.04087674627839573, 0.012463592572435235, 0.025297778398393568, 0.024814023024414673, 0.025987440909028277, 0.07499905801517684, 0.029700226333322706, 0.0524615488268907, 0.055021692956443, 0.010093139628082736, 0.04259519513648398, 0.04922736168343139, 0.057530105746394264, 0.021629669152146303, 0.0181909967817958, 0.10129082810533761, 0.015607824630063178], [0.02995774684943825, 0.0, 0.02850266140601373, 0.01947649363748378, 0.03984230632099588, 0.040052448796382395, 0.014595994457653935, 0.020430240011812106, 0.018803552474684643, 0.051793906234511744, 0.01766017602087586, 0.037230400755704385, 0.005611698717481173, 0.03706558189966358, 1.0000000000000002, 0.0, 0.0, 0.005573530402071209, 0.024978422482067872, 0.0648797556521374, 0.03972188838758203, 0.03399786194069356, 0.02023965038067286, 0.059386349854446414, 0.001332613167410867, 0.08353433988064235, 0.02026807103870688, 0.014170703277900216, 0.04659249507998253, 0.043300024282500224, 0.05528710102369801, 0.011009838665022509], [0.03347700360493521, 0.0, 0.024779744596907568, 0.014527111510612306, 0.0, 0.016859495304394005, 0.0, 0.029513687029471894, 0.07313242888478778, 0.0, 0.0, 0.0, 0.0, 0.04087674627839573, 0.0, 0.9999999999999999, 0.0, 0.0, 0.0, 0.03158481020272256, 0.0, 0.0, 0.057048610638581604, 0.033056675020858635, 0.0, 0.06245189681694787, 0.0, 0.029057314736843864, 0.038968159627792126, 0.030375525068784187, 0.019499253905019887, 0.0], [0.0, 0.0, 0.0, 0.030648750724538355, 0.0, 0.0219109292228047, 0.0, 0.0, 0.0, 0.017039808705854656, 0.09329024736354027, 0.0, 0.02245562510499821, 0.012463592572435235, 0.0, 0.0, 0.9999999999999998, 0.011603619514050714, 0.0, 0.0, 0.017083967313060097, 0.0, 0.0, 0.0074043964833490445, 0.013492141972680562, 0.011246511873401295, 0.013184100529048861, 0.03171928592423446, 0.024764475499641093, 0.0, 0.0, 0.0805316486274864], [0.0, 0.01399798246495333, 0.0, 0.034964055514936615, 0.025124553117476446, 0.042146645338000804, 0.0, 0.008005277392453766, 0.00741490351195898, 0.03082587064843032, 0.018844507109407247, 0.02002816198155088, 0.037194047413175044, 0.025297778398393568, 0.005573530402071209, 0.0, 0.011603619514050714, 1.0, 0.0, 0.009714607416334937, 0.033489239473500916, 0.0033168510305547536, 0.026189406123943992, 0.03545818918285534, 0.008778838835841761, 0.040504964702762984, 0.017659090689692437, 0.030263998897218574, 0.055669543418152806, 0.07607018729385928, 0.034820671790278, 0.02684784126260703], [0.0, 0.01352311174055609, 0.015760799148422846, 0.012019506362548001, 0.0, 0.027477411820976974, 0.0, 0.0, 0.00727119772973515, 0.015190333286882697, 0.00536679358457379, 0.0, 0.009971889527869947, 0.024814023024414673, 0.024978422482067872, 0.0, 0.0, 0.0, 0.9999999999999999, 0.0250086231668343, 0.014320829417693496, 0.03380798571236949, 0.0236964469191678, 0.003288076969902338, 0.0, 0.01620330581361451, 0.03950808080213203, 0.03099486653312298, 0.005364419146400547, 0.0, 0.014368421916653567, 0.01239564560145538], [0.0, 0.0, 0.03331486014006675, 0.017198739557807333, 0.011837467555193711, 0.04865379402040577, 0.01774804261280075, 0.01077454623376135, 0.017672696596159415, 0.08014477137778735, 0.002276511186533275, 0.009176972155185266, 0.013811318257831722, 0.025987440909028277, 0.0648797556521374, 0.03158481020272256, 0.0, 0.009714607416334937, 0.0250086231668343, 1.0000000000000004, 0.003325681912255651, 0.014340826874652097, 0.017533163626578335, 0.03328058623530883, 0.014422129686111795, 0.023651211089712555, 0.031380105578603684, 0.04142239683638839, 0.024997217124120195, 0.0, 0.0, 0.007687625064371241], [0.024185541482555778, 0.03492570531470705, 0.0, 0.04188795659983768, 0.0987522163342077, 0.024237098035176638, 0.02283798917517596, 0.0, 0.01975653236993719, 0.053951258713314826, 0.012188265150703599, 0.02247589713324245, 0.022969192044374885, 0.07499905801517684, 0.03972188838758203, 0.0, 0.017083967313060097, 0.033489239473500916, 0.014320829417693496, 0.003325681912255651, 0.9999999999999999, 0.033412288264509704, 0.061600432270586286, 0.04302635998844625, 0.011554338221945832, 0.016685495493929437, 0.027155764289425267, 0.04260739889874465, 0.05421459601984026, 0.0015138902947611122, 0.09624142177230059, 0.028688262222037093], [0.0, 0.0045491076020615666, 0.0, 0.029678156208540498, 0.031221273033637954, 0.02068716122493726, 0.018809556013095488, 0.003514332057694603, 0.040688696961614305, 0.018584245292861578, 0.015598068154640684, 0.010012987469039107, 0.0068174310703912125, 0.029700226333322706, 0.03399786194069356, 0.0, 0.0, 0.0033168510305547536, 0.03380798571236949, 0.014340826874652097, 0.033412288264509704, 1.0, 0.012188808284663769, 0.005701272996126935, 0.01195501803038374, 0.02194189209857569, 0.006619495543067105, 0.0030679753264307883, 0.003667465194140041, 0.032321874548642604, 0.01644571129061412, 0.009974088484714592], [0.009177640949648395, 0.006272875226497045, 0.018190441707578265, 0.017894047711639192, 0.03646127087890035, 0.030413242373896945, 0.008876804630658142, 0.025154410654098656, 0.0375877917325347, 0.05394101197287035, 0.012299877816716763, 0.01214364587682357, 0.0, 0.0524615488268907, 0.02023965038067286, 0.057048610638581604, 0.0, 0.026189406123943992, 0.0236964469191678, 0.017533163626578335, 0.061600432270586286, 0.012188808284663769, 1.0, 0.04153724762185301, 0.022297062806135873, 0.03164086043931865, 0.016952651209241647, 0.06500838133089702, 0.03523672783790849, 0.010342593453345776, 0.049853344622021324, 0.013175670669515114], [0.006095317847094681, 0.029295935854436052, 0.0559807234641116, 0.01309298651004118, 0.025032329716393506, 0.03625186911227815, 0.03617634741060122, 0.0, 0.03602757489001831, 0.04659013379082574, 0.006894897685942395, 0.013254425006324951, 0.038048497344584736, 0.055021692956443, 0.059386349854446414, 0.033056675020858635, 0.0074043964833490445, 0.03545818918285534, 0.003288076969902338, 0.03328058623530883, 0.04302635998844625, 0.005701272996126935, 0.04153724762185301, 0.9999999999999998, 0.016518520397363727, 0.005325482554151109, 0.032519351158622145, 0.06106465974445468, 0.08376814996267773, 0.0009536000074124221, 0.07124073155277212, 0.021821642814568033], [0.0, 0.006703007880556978, 0.0, 0.01640818700990469, 0.016709587351972054, 0.019610860383996287, 0.01755442187880152, 0.020305107166654988, 0.011100262854647994, 0.027665142358011725, 0.0015632435649459062, 0.0, 0.0, 0.010093139628082736, 0.001332613167410867, 0.0, 0.013492141972680562, 0.008778838835841761, 0.0, 0.014422129686111795, 0.011554338221945832, 0.01195501803038374, 0.022297062806135873, 0.016518520397363727, 0.9999999999999999, 0.017229043924284114, 0.020146312682282317, 0.011884293815088627, 0.004051330466862573, 0.02086024172575788, 0.028856760879540578, 0.021057594377924153], [0.016427908691655866, 0.016643481998781184, 0.010698539317989144, 0.04522156669342009, 0.03358543678990562, 0.03461381499858542, 0.0204261718538951, 0.04020884146172763, 0.027011720839772102, 0.020327569810081894, 0.023982454676052204, 0.0056585761440093, 0.00676898748495482, 0.04259519513648398, 0.08353433988064235, 0.06245189681694787, 0.011246511873401295, 0.040504964702762984, 0.01620330581361451, 0.023651211089712555, 0.016685495493929437, 0.02194189209857569, 0.03164086043931865, 0.005325482554151109, 0.017229043924284114, 1.0000000000000002, 0.014897888333724315, 0.01615845507119359, 0.017253362729950514, 0.08642585986598375, 0.019805297023117945, 0.017114102528287968], [0.0, 0.022561905048625215, 0.015537965621719519, 0.10806945435374424, 0.02745667460221717, 0.1128635260691559, 0.020180000640012418, 0.024054556794098503, 0.05062928049630758, 0.06000428541975659, 0.02515978287256293, 0.02203323366191245, 0.017091526695916688, 0.04922736168343139, 0.02026807103870688, 0.0, 0.013184100529048861, 0.017659090689692437, 0.03950808080213203, 0.031380105578603684, 0.027155764289425267, 0.006619495543067105, 0.016952651209241647, 0.032519351158622145, 0.020146312682282317, 0.014897888333724315, 1.0000000000000007, 0.01809854024774864, 0.066615236774527, 0.010487093805623, 0.06760635706395322, 0.0267133785498071], [0.0, 0.03399415142819739, 0.09438274524840802, 0.012531257531369383, 0.030979119541277807, 0.03420295532210278, 0.0014355181495482134, 0.010403309402163835, 0.0423809215098252, 0.039838312578969776, 0.013694784314910145, 0.010185199002412998, 0.0, 0.057530105746394264, 0.014170703277900216, 0.029057314736843864, 0.03171928592423446, 0.030263998897218574, 0.03099486653312298, 0.04142239683638839, 0.04260739889874465, 0.0030679753264307883, 0.06500838133089702, 0.06106465974445468, 0.011884293815088627, 0.01615845507119359, 0.01809854024774864, 1.0000000000000002, 0.019535362691424876, 0.001635015445020478, 0.053386926913070364, 0.02764702902356523], [0.0, 0.015470343168410467, 0.05808365159698793, 0.010792209366116924, 0.030086033834475216, 0.037833346112215595, 0.05949297374985423, 0.0, 0.04632683399728664, 0.028541137095132348, 0.0035412952849974712, 0.019018574972320946, 0.006579982034163878, 0.021629669152146303, 0.04659249507998253, 0.038968159627792126, 0.024764475499641093, 0.055669543418152806, 0.005364419146400547, 0.024997217124120195, 0.05421459601984026, 0.003667465194140041, 0.03523672783790849, 0.08376814996267773, 0.004051330466862573, 0.017253362729950514, 0.066615236774527, 0.019535362691424876, 0.9999999999999997, 0.006000804485983621, 0.03799339502695772, 0.003757552863971032], [0.03916136295235433, 0.0, 0.0, 0.07342913806674714, 0.017044955717240236, 0.06809644056164116, 0.0012770107671980396, 0.050897908104059204, 0.036389870203980164, 0.010323827270926487, 0.0015564642947462732, 0.0, 0.0, 0.0181909967817958, 0.043300024282500224, 0.030375525068784187, 0.0, 0.07607018729385928, 0.0, 0.0, 0.0015138902947611122, 0.032321874548642604, 0.010342593453345776, 0.0009536000074124221, 0.02086024172575788, 0.08642585986598375, 0.010487093805623, 0.001635015445020478, 0.006000804485983621, 1.0, 0.030892031842345163, 0.00994060804597145], [0.021935268723387857, 0.011488014495506224, 0.02757936399824741, 0.054247107800793906, 0.06337159262503775, 0.0370982708170593, 0.00541857810196316, 0.03522308761712385, 0.01766229709438904, 0.0465532869382955, 0.013875907062360904, 0.03399595240182782, 0.004979287464230278, 0.10129082810533761, 0.05528710102369801, 0.019499253905019887, 0.0, 0.034820671790278, 0.014368421916653567, 0.0, 0.09624142177230059, 0.01644571129061412, 0.049853344622021324, 0.07124073155277212, 0.028856760879540578, 0.019805297023117945, 0.06760635706395322, 0.053386926913070364, 0.03799339502695772, 0.030892031842345163, 0.9999999999999991, 0.022552394945273814], [0.005071740758464668, 0.019453471984443523, 0.0, 0.0, 0.02262135961222175, 0.032201746045954174, 0.0028908355760221844, 0.007391266699602124, 0.028232601931543592, 0.03874797810427858, 0.044716371329394225, 0.018707288883587532, 0.0, 0.015607824630063178, 0.011009838665022509, 0.0, 0.0805316486274864, 0.02684784126260703, 0.01239564560145538, 0.007687625064371241, 0.028688262222037093, 0.009974088484714592, 0.013175670669515114, 0.021821642814568033, 0.021057594377924153, 0.017114102528287968, 0.0267133785498071, 0.02764702902356523, 0.003757552863971032, 0.00994060804597145, 0.022552394945273814, 1.0]]]], \"left_text\": [\"comp.graphics 0\", \"sci.space 0\", \"sci.space 1\", \"comp.graphics 1\", \"alt.atheism 0\", \"comp.graphics 2\", \"sci.space 2\", \"comp.graphics 3\", \"sci.space 3\", \"rec.autos 0\", \"rec.autos 1\", \"alt.atheism 1\", \"alt.atheism 2\", \"alt.atheism 3\", \"comp.graphics 4\", \"sci.space 4\", \"rec.autos 2\", \"comp.graphics 5\", \"comp.graphics 6\", \"sci.space 5\", \"alt.atheism 4\", \"sci.space 6\", \"sci.space 7\", \"sci.space 8\", \"rec.autos 3\", \"alt.atheism 5\", \"comp.graphics 7\", \"sci.space 9\", \"sci.space 10\", \"comp.graphics 8\", \"alt.atheism 6\", \"rec.autos 4\"], \"right_text\": [\"comp.graphics 0\", \"sci.space 0\", \"sci.space 1\", \"comp.graphics 1\", \"alt.atheism 0\", \"comp.graphics 2\", \"sci.space 2\", \"comp.graphics 3\", \"sci.space 3\", \"rec.autos 0\", \"rec.autos 1\", \"alt.atheism 1\", \"alt.atheism 2\", \"alt.atheism 3\", \"comp.graphics 4\", \"sci.space 4\", \"rec.autos 2\", \"comp.graphics 5\", \"comp.graphics 6\", \"sci.space 5\", \"alt.atheism 4\", \"sci.space 6\", \"sci.space 7\", \"sci.space 8\", \"rec.autos 3\", \"alt.atheism 5\", \"comp.graphics 7\", \"sci.space 9\", \"sci.space 10\", \"comp.graphics 8\", \"alt.atheism 6\", \"rec.autos 4\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-259bed898bfe4c7c8f550a89eb9a061d\", \"layer\": null, \"heads\": null, \"include_layers\": [0]} is a template marker that is replaced by actual params.\n    const TEXT_SIZE = 15;\n    const BOXWIDTH = 110;\n    const BOXHEIGHT = 22.5;\n    const MATRIX_WIDTH = 115;\n    const CHECKBOX_SIZE = 20;\n    const TEXT_TOP = 30;\n\n    console.log(\"d3 version\", d3.version)\n    let headColors;\n    try {\n        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n    } catch (err) {\n        console.log('Older d3 version')\n        headColors = d3.scale.category10();\n    }\n    let config = {};\n    initialize();\n    renderVis();\n\n    function initialize() {\n        config.attention = params['attention'];\n        config.filter = params['default_filter'];\n        config.rootDivId = params['root_div_id'];\n        config.nLayers = config.attention[config.filter]['attn'].length;\n        config.nHeads = config.attention[config.filter]['attn'][0].length;\n        config.layers = params['include_layers']\n\n        if (params['heads']) {\n            config.headVis = new Array(config.nHeads).fill(false);\n            params['heads'].forEach(x => config.headVis[x] = true);\n        } else {\n            config.headVis = new Array(config.nHeads).fill(true);\n        }\n        config.initialTextLength = config.attention[config.filter].right_text.length;\n        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n        config.layer = config.layers[config.layer_seq]\n\n        let layerEl = $(`#${config.rootDivId} #layer`);\n        for (const layer of config.layers) {\n            layerEl.append($(\"<option />\").val(layer).text(layer));\n        }\n        layerEl.val(config.layer).change();\n        layerEl.on('change', function (e) {\n            config.layer = +e.currentTarget.value;\n            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n            renderVis();\n        });\n\n        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n            config.filter = e.currentTarget.value;\n            renderVis();\n        });\n    }\n\n    function renderVis() {\n\n        // Load parameters\n        const attnData = config.attention[config.filter];\n        const leftText = attnData.left_text;\n        const rightText = attnData.right_text;\n\n        // Select attention for given layer\n        const layerAttention = attnData.attn[config.layer_seq];\n\n        // Clear vis\n        $(`#${config.rootDivId} #vis`).empty();\n\n        // Determine size of visualization\n        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n        const svg = d3.select(`#${config.rootDivId} #vis`)\n            .append('svg')\n            .attr(\"width\", \"100%\")\n            .attr(\"height\", height + \"px\");\n\n        // Display tokens on left and right side of visualization\n        renderText(svg, leftText, true, layerAttention, 0);\n        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n\n        // Render attention arcs\n        renderAttention(svg, layerAttention);\n\n        // Draw squares at top of visualization, one for each head\n        drawCheckboxes(0, svg, layerAttention);\n    }\n\n    function renderText(svg, text, isLeft, attention, leftPos) {\n\n        const textContainer = svg.append(\"svg:g\")\n            .attr(\"id\", isLeft ? \"left\" : \"right\");\n\n        // Add attention highlights superimposed over words\n        textContainer.append(\"g\")\n            .classed(\"attentionBoxes\", true)\n            .selectAll(\"g\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\"rect\")\n            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function () {\n                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n                return leftPos + boxOffsets(headIndex);\n            })\n            .attr(\"y\", (+1) * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH / activeHeads())\n            .attr(\"height\", BOXHEIGHT)\n            .attr(\"fill\", function () {\n                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n            })\n            .style(\"opacity\", 0.0);\n\n        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n            .data(text)\n            .enter()\n            .append(\"g\");\n\n        // Add gray background that appears when hovering over text\n        tokenContainer.append(\"rect\")\n            .classed(\"background\", true)\n            .style(\"opacity\", 0.0)\n            .attr(\"fill\", \"lightgray\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n            .attr(\"width\", BOXWIDTH)\n            .attr(\"height\", BOXHEIGHT);\n\n        // Add token text\n        const textEl = tokenContainer.append(\"text\")\n            .text(d => d)\n            .attr(\"font-size\", TEXT_SIZE + \"px\")\n            .style(\"cursor\", \"default\")\n            .style(\"-webkit-user-select\", \"none\")\n            .attr(\"x\", leftPos)\n            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n\n        if (isLeft) {\n            textEl.style(\"text-anchor\", \"end\")\n                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        } else {\n            textEl.style(\"text-anchor\", \"start\")\n                .attr(\"dx\", +0.5 * TEXT_SIZE)\n                .attr(\"dy\", TEXT_SIZE);\n        }\n\n        tokenContainer.on(\"mouseover\", function (d, index) {\n\n            // Show gray background for moused-over token\n            textContainer.selectAll(\".background\")\n                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n\n            // Reset visibility attribute for any previously highlighted attention arcs\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null)\n\n            // Hide group containing attention arcs\n            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n\n            // Set to visible appropriate attention arcs to be highlighted\n            if (isLeft) {\n                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            } else {\n                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n            }\n\n            // Update color boxes superimposed over tokens\n            const id = isLeft ? \"right\" : \"left\";\n            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n            svg.select(\"#\" + id)\n                .selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .attr(\"head-index\", (d, i) => i)\n                .selectAll(\"rect\")\n                .attr(\"x\", function () {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    return leftPos + boxOffsets(headIndex);\n                })\n                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n                .attr(\"width\", BOXWIDTH / activeHeads())\n                .attr(\"height\", BOXHEIGHT)\n                .style(\"opacity\", function (d) {\n                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n                    if (config.headVis[headIndex])\n                        if (d) {\n                            return d[index];\n                        } else {\n                            return 0.0;\n                        }\n                    else\n                        return 0.0;\n                });\n        });\n\n        textContainer.on(\"mouseleave\", function () {\n\n            // Unhighlight selected token\n            d3.select(this).selectAll(\".background\")\n                .style(\"opacity\", 0.0);\n\n            // Reset visibility attributes for previously selected lines\n            svg.select(\"#attention\")\n                .selectAll(\"line[visibility='visible']\")\n                .attr(\"visibility\", null) ;\n            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n\n            // Reset highlights superimposed over tokens\n            svg.selectAll(\".attentionBoxes\")\n                .selectAll(\"g\")\n                .selectAll(\"rect\")\n                .style(\"opacity\", 0.0);\n        });\n    }\n\n    function renderAttention(svg, attention) {\n\n        // Remove previous dom elements\n        svg.select(\"#attention\").remove();\n\n        // Add new elements\n        svg.append(\"g\")\n            .attr(\"id\", \"attention\") // Container for all attention arcs\n            .selectAll(\".headAttention\")\n            .data(attention)\n            .enter()\n            .append(\"g\")\n            .classed(\"headAttention\", true) // Group attention arcs by head\n            .attr(\"head-index\", (d, i) => i)\n            .selectAll(\".tokenAttention\")\n            .data(d => d)\n            .enter()\n            .append(\"g\")\n            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n            .attr(\"left-token-index\", (d, i) => i)\n            .selectAll(\"line\")\n            .data(d => d)\n            .enter()\n            .append(\"line\")\n            .attr(\"x1\", BOXWIDTH)\n            .attr(\"y1\", function () {\n                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n            })\n            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n            .attr(\"stroke-width\", 2)\n            .attr(\"stroke\", function () {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                return headColors(headIndex)\n            })\n            .attr(\"left-token-index\", function () {\n                return +this.parentNode.getAttribute(\"left-token-index\")\n            })\n            .attr(\"right-token-index\", (d, i) => i)\n        ;\n        updateAttention(svg)\n    }\n\n    function updateAttention(svg) {\n        svg.select(\"#attention\")\n            .selectAll(\"line\")\n            .attr(\"stroke-opacity\", function (d) {\n                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n                // If head is selected\n                if (config.headVis[headIndex]) {\n                    // Set opacity to attention weight divided by number of active heads\n                    return d / activeHeads()\n                } else {\n                    return 0.0;\n                }\n            })\n    }\n\n    function boxOffsets(i) {\n        const numHeadsAbove = config.headVis.reduce(\n            function (acc, val, cur) {\n                return val && cur < i ? acc + 1 : acc;\n            }, 0);\n        return numHeadsAbove * (BOXWIDTH / activeHeads());\n    }\n\n    function activeHeads() {\n        return config.headVis.reduce(function (acc, val) {\n            return val ? acc + 1 : acc;\n        }, 0);\n    }\n\n    function drawCheckboxes(top, svg) {\n        const checkboxContainer = svg.append(\"g\");\n        const checkbox = checkboxContainer.selectAll(\"rect\")\n            .data(config.headVis)\n            .enter()\n            .append(\"rect\")\n            .attr(\"fill\", (d, i) => headColors(i))\n            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n            .attr(\"y\", top)\n            .attr(\"width\", CHECKBOX_SIZE)\n            .attr(\"height\", CHECKBOX_SIZE);\n\n        function updateCheckboxes() {\n            checkboxContainer.selectAll(\"rect\")\n                .data(config.headVis)\n                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n        }\n\n        updateCheckboxes();\n\n        checkbox.on(\"click\", function (d, i) {\n            if (config.headVis[i] && activeHeads() === 1) return;\n            config.headVis[i] = !config.headVis[i];\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n\n        checkbox.on(\"dblclick\", function (d, i) {\n            // If we double click on the only active head then reset\n            if (config.headVis[i] && activeHeads() === 1) {\n                config.headVis = new Array(config.nHeads).fill(true);\n            } else {\n                config.headVis = new Array(config.nHeads).fill(false);\n                config.headVis[i] = true;\n            }\n            updateCheckboxes();\n            updateAttention(svg);\n        });\n    }\n\n    function lighten(color) {\n        const c = d3.hsl(color);\n        const increment = (1 - c.l) * 0.6;\n        c.l += increment;\n        c.s -= increment;\n        return c;\n    }\n\n    function transpose(mat) {\n        return mat[0].map(function (col, i) {\n            return mat.map(function (row) {\n                return row[i];\n            });\n        });\n    }\n\n});",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"rec.autos\",\n",
    "    \"comp.graphics\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(\n",
    "    subset=\"train\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=(),\n",
    ")\n",
    "data_test = fetch_20newsgroups(\n",
    "    subset=\"test\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=(),\n",
    ")\n",
    "\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "!pip install bertviz\n",
    "from bertviz import head_view, model_view\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "# split target in a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "# Extracting features from the training data using a sparse vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True, max_df=0.5, min_df=5, stop_words=\"english\"\n",
    ")\n",
    "X_train = vectorizer.fit_transform(data_train.data)\n",
    "\n",
    "# Extracting features from the test data using the same vectorizer\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "seq = X_test[:32,:]\n",
    "b = seq.toarray()\n",
    "att = b@b.T\n",
    "att = att.reshape(1,1,32,32)\n",
    "att = torch.tensor(att)\n",
    "counts = [0,0,0,0]\n",
    "tokens = []\n",
    "for i in y_test[:32]:\n",
    "  token = target_names[i] + ' ' + str(counts[i])\n",
    "  tokens.append(token)\n",
    "  counts[i]+=1\n",
    "head_view((att,), tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Essa visualização representa uma matriz de atenção 32x32 aplicada a um conjunto de 32 amostras compostas por uma frase (vetor) e um output (classe). Essa matriz de atenção é construída a partir do produto entre b e bT, onde b é uma matriz com 32 linhas (cada amostra) e 8025 colunas (tamanho do vocabulário de treino definido pelo modelo de vetorização). Note que essa matriz att (definida pelo produto interno 2 a 2 entre os vetores que representam o input) representa a relação entre as amostras e portanto carrega consigo a relação entre o output. Assim, plotamos como cada output relaciona com os outros de acordo com a matriz de atenção. Podemos abstrair essa atenção como uma representação de correlação entre outputs.\n",
    "\n",
    "\n",
    "### OBS: Note que o input aqui é uma matriz de 8025 colunas representando uma frase/texto que é basicamente uma contagem da quantidade de vezes que uma palavra i aparece na frase ponderado pelo inverso das vezes que essa palavra aparece no conjunto completo dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Note que o cosseno captura uma noção de distância compreensível quando é possível se obter intersecção entre os vetores na direção definida por seus versores. Do contrário, quando tais direções definem subespaços reversos, o cosseno se torna de difícil interpretação. Além disso, quando estrapolamos o angulo para valores fora do primeiro quadrante, notamos que o cosseno passa a retornar valores negativos, distorcendo a interpretabilidade da métrica e retornando \"distancias\" de mesmo modulo apesar dos vetores estarem mais distantes.\n",
    "\n",
    "### Ao limitar-se o dominio do problema (ou caso distancias negativas sejam uma metrica desejavel), o cosseno pode se mostrar mais vantajoso. Do contrario, a distancia euclidiana se adequa melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# c)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m X_train \u001b[38;5;241m=\u001b[39m (X_train\u001b[38;5;241m-\u001b[39mX_train\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;241m/\u001b[39mX_train\u001b[38;5;241m.\u001b[39mstd()\n\u001b[0;32m      5\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32mc:\\Users\\bielv\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# c)\n",
    "\n",
    "X_train = torch.tensor(X_train.toarray(), dtype=torch.float32).cuda()\n",
    "X_train = (X_train-X_train.mean())/X_train.std()\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).cuda()\n",
    "X_test = torch.tensor(X_test.toarray(), dtype=torch.float32).cuda()\n",
    "X_test = (X_test-X_test.mean())/X_test.std()\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).cuda()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "n_epochs = 5\n",
    "lr = 1e-5\n",
    "sequence_length = 32\n",
    "\n",
    "def init_scale(fan_in):\n",
    "    return (2/fan_in)**.5\n",
    "\n",
    "D = X_train.shape[1]\n",
    "\n",
    "A_K = torch.randn((D,D)).cuda()#*init_scale(D)\n",
    "A_Q = torch.randn((D,D)).cuda()#*init_scale(D)\n",
    "\n",
    "A_K.requires_grad = True\n",
    "A_Q.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.Adam([A_K, A_Q], lr = lr)\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "cos = torch.nn.CosineSimilarity(dim=0)\n",
    "losses = []\n",
    "for epoch in range(n_epochs):\n",
    "  permutation = torch.randperm(X_train.shape[0])\n",
    "  for i in range(0,X_train.shape[0], sequence_length):\n",
    "    optimizer.zero_grad()\n",
    "    indices = permutation[i:i+sequence_length]\n",
    "    if len(indices)!=sequence_length:\n",
    "      continue\n",
    "    seq_X, seq_Y = X_train[indices], y_train[indices]\n",
    "\n",
    "    K = A_K@(seq_X.T)\n",
    "    Q = A_Q@(seq_X.T)\n",
    "    att = softmax((K.T@Q)/(D**(1/2)))\n",
    "    truth = ((seq_Y-seq_Y.reshape(-1,1))==0).type(torch.float32)\n",
    "    loss = -cos(att,truth).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.detach().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
